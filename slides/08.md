---
presentation:
  margin: 0
  center: false
  transition: "convex"
  enableSpeakerNotes: true
  slideNumber: "c/t"
  navigationMode: "linear"
---

@import "../css/font-awesome-4.7.0/css/font-awesome.css"
@import "../css/theme/solarized.css"
@import "../css/logo.css"
@import "../css/font.css"
@import "../css/color.css"
@import "../css/margin.css"
@import "../css/table.css"
@import "../css/main.css"
@import "../plugin/zoom/zoom.js"
@import "../plugin/customcontrols/plugin.js"
@import "../plugin/customcontrols/style.css"
@import "../plugin/chalkboard/plugin.js"
@import "../plugin/chalkboard/style.css"
@import "../plugin/menu/menu.js"
@import "../js/anychart/anychart-core.min.js"
@import "../js/anychart/anychart-venn.min.js"
@import "../js/anychart/pastel.min.js"
@import "../js/anychart/venn-ml.js"

<!-- slide data-notes="" -->

<div class="bottom20"></div>

# 机器学习

<hr class="width50 center">

## 朴素贝叶斯

<div class="bottom8"></div>

### 计算机学院 &nbsp;&nbsp; 张腾

#### _tengzhang@hust.edu.cn_

<!-- slide vertical=true data-notes="" -->

##### 大纲

---

@import "../vega/outline.json" {as="vega" .top-2}

<!-- slide data-notes="" -->

##### 贝叶斯决策论

---

- 样本空间$\Xcal \subseteq \Fbb^d$，类别标记空间为$\Ycal$
- $\Dcal$是$\Xcal \times \Ycal$上的未知概率分布，概率密度函数为$\Pbb(\xv, y)$
- 损失函数$\ell: \Ycal \times \Ycal \mapsto \Rbb$

学习器$h: \Xcal \mapsto \Ycal$的泛化风险为

$$
\begin{align*}
    \qquad R_{\Dcal} (h) & = \Ebb_{(\xv,y) \sim \Dcal} [\ell(y, h(\xv))] = \iint \ell(y, h(\xv)) \Pbb(\xv, y) \diff \xv \diff y \\
    & = \int \left( \int \ell(y, h(\xv)) \Pbb(y|\xv) \diff y \right) \Pbb(\xv) \diff \xv \\
    & = \Ebb_{\xv} \left[ \int \ell(y, h(\xv)) \Pbb(y|\xv) \diff y \right] = \Ebb_{\xv} [ \Ebb_y [\ell(y, h(\xv)) | \xv]]
\end{align*}
$$

<div class="top-4"></div>

最小泛化风险称为{==贝叶斯风险==}，对应的$h^\star$即{==贝叶斯最优学习器==}

$$
\begin{align*}
    \qquad h^\star(\xv) = \mathop{\arg\min}_{h(\xv)} \int \ell(y, h(\xv)) \Pbb(y|\xv) \diff y
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 贝叶斯最优学习器

---

<div class="top2"></div>

$$
\begin{align*}
    \qquad h^\star(\xv) = \mathop{\arg\min}_{h(\xv)} \int \ell(y, h(\xv)) \Pbb(y|\xv) \diff y
\end{align*}
$$

<div class="top-4"></div>

回归问题通常采用平方损失$\ell(y, h(\xv)) = (y - h(\xv))^2$

$$
\begin{align*}
    \qquad \nabla_{h(\xv)} \left( \int (y - h(\xv))^2 \Pbb(y|\xv) \diff y \right) & = 2 \int (h(\xv) - y) \Pbb(y|\xv) \diff y \\
    & = 2 h(\xv) - 2 \int y \Pbb(y|\xv) \diff y \\
    & = 2 h(\xv) - 2 \Ebb[y|\xv]
\end{align*}
$$

<div class="top-4"></div>

即回归问题的贝叶斯最优模型$h^\star(\xv) = \Ebb[y|\xv]$

我的批注 在偏差方差分解中我们曾得到相同的结论

$$
\begin{align*}
    \qquad \Ebb_{(\xv,y) \sim \Dcal} [(y - h(\xv))^2] = \Ebb_{\xv} [(h(\xv) - \Ebb [y|\xv])^2] + \noise
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 贝叶斯最优学习器

---

<div class="top2"></div>

$$
\begin{align*}
    \qquad h^\star(\xv) = \mathop{\arg\min}_{h(\xv)} \int \ell(y, h(\xv)) \Pbb(y|\xv) \diff y
\end{align*}
$$

<div class="top-4"></div>

对分类问题，设$\Ycal = [c]$，$\ell(y, h(\xv)) = \Ibb(y \ne h(\xv))$，则

<div class="top1"></div>

$$
\begin{align*}
    \qquad h^\star(\xv) & = \mathop{\arg\min}_{\yhat \in [c]} \sum_{y \in [c]} \Ibb(y \ne \yhat) \Pbb(y|\xv) \\[4pt]
    & = \mathop{\arg\min}_{\yhat \in [c]} ~ (1 - \Pbb(\yhat|\xv)) \\[4pt]
    & = \mathop{\arg\max}_{\yhat \in [c]} ~ \Pbb(\yhat|\xv)
\end{align*}
$$

<div class="top-4"></div>

即分类问题的贝叶斯最优模型$h^\star(\xv) = \mathop{\arg\max}_{\yhat \in [c]} \Pbb(\yhat|\xv)$

我的批注 对于分类问题，{==泛化风险最小化==}等价于{==后验概率最大化==}

<!-- slide data-notes="" -->

##### 判别式 _vs._ 生成式

---

后验概率最大化的两种实现方式：判别式方法、生成式方法

判别式方法：直接用线性判别式拟合后验概率，如对率回归

$$
\begin{align*}
    \quad [\Pbb(y=1|\xv), \ldots, \Pbb(y=c|\xv)] = \softmax (\wv_1^\top \xv, \ldots, \wv_c^\top \xv)
\end{align*}
$$

生成式方法：迂回策略，用贝叶斯公式从数据的生成机制入手

$$
\begin{align*}
    \quad \Pbb(y|\xv) & = \frac{\class{yellow}{\Pbb(y)} \times \class{blue}{\Pbb(\xv|y)}}{\Pbb(\xv)}
    \Longrightarrow \begin{cases} \Pbb(y = 1 | \xv) \propto \class{yellow}{\Pbb(y=1)} \times \class{blue}{\Pbb(\xv|y=1)} \\
    \qquad \vdots \\
    \Pbb(y = c | \xv) \propto \class{yellow}{\Pbb(y=c)} \times \class{blue}{\Pbb(\xv|y=c)} \end{cases} \\[10pt]
    & \Longrightarrow \mathop{\arg \max}_{y \in [c]} \Pbb(y|\xv) = \mathop{\arg \max}_{y \in [c]} \Pbb(y) \Pbb(\xv | y)
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 朴素贝叶斯

---

<div class="top2"></div>

$$
\begin{align*}
    \qquad \mathop{\arg \max}_{y \in [c]} \Pbb(y|\xv) = \mathop{\arg \max}_{y \in [c]} \Pbb(y) \Pbb(\xv | y)
\end{align*}
$$

<div class="top-4"></div>

注意$\xv = [x_1; x_2; \ldots; x_d]$，于是似然

$$
\begin{align*}
    \qquad \Pbb(\xv | y) = \Pbb(x_1 | y) \Pbb(x_2 | x_1, y) \cdots \Pbb(x_d | x_{d-1}, \ldots, x_2, x_1, y)
\end{align*}
$$

<div class="top-3"></div>

当特征数$d$很大时似然会很难计算 (要考虑所有特征的所有取值)

<div class="top4"></div>

朴素贝叶斯 (<u>n</u>aïve <u>B</u>ayes, NB) 引入{==条件独立性假设==}：

$$
\begin{align*}
    \qquad \Pbb(\xv | y) = \Pbb(x_1 | y) \Pbb(x_2 | y) \cdots \Pbb(x_d | y) = \prod_{j \in [d]} \Pbb(x_j | y)
\end{align*}
$$

<div class="top-2"></div>

问题：如何用数据集估计$\Pbb(y), ~ \Pbb(x_1 | y), ~ \Pbb(x_2 | y), ~ \ldots, ~ \Pbb(x_d | y)$

<!-- slide data-notes="" -->

##### 从数据中估计参数

---

<div class="top2"></div>

$$
\begin{align*}
    \qquad \Pbb(y | \xv) = \Pbb(y) \Pbb(x_1 | y) \Pbb(x_2 | y) \cdots \Pbb(x_d | y)
\end{align*}
$$

对于先验，记参数$\alpha_k = \Pbb(y = k)$，于是

$$
\begin{align*}
    \qquad \Pbb(y | \alpha_k) = \prod_{k \in [c]} \Pbb(y = k)^{\Ibb(y=k)} = \prod_{k \in [c]} \alpha_k^{\Ibb(y=k)}
\end{align*}
$$

对于似然，设第$j$个特征共有$n_j$种不同取值$v_1^{(j)}, \ldots, v_{n_j}^{(j)}$

<div class="top-2"></div>

记参数$\theta_{jlk} = \Pbb( x_j = v_l^{(j)} | y=k)$，于是对$\forall j \in [d]$和$\forall k \in [c]$有

$$
\begin{align*}
    \qquad & \Pbb(x_j | y = k, \theta_{jlk}) = \prod_{l \in [n_j]} \Pbb( x_j = v_l^{(j)} | y=k)^{\Ibb(x_j = v_l^{(j)})} = \prod_{l \in [n_j]} \theta_{jlk}^{\Ibb(x_j = v_l^{(j)})} \\
    & \sum_{l \in [n_j]} \theta_{jlk} = 1
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 从数据中估计参数

---

设数据集$D = \{ (\xv^{(i)}, y^{(i)}) \}_{i \in [m]}$，对数似然函数：

$$
\begin{align*}
    \quad \mathrm{LL} & = \log \Pbb(D | \alphav, \thetav) = \sum_{i \in [m]} \log \Pbb(\xv^{(i)}, y^{(i)} | \alphav, \thetav) \\
    & = \sum_{i \in [m]} \log \prod_{k \in [c]} \Pbb(\xv^{(i)}, y^{(i)} = k | \alphav, \thetav)^{\Ibb(y^{(i)}=k)} \\
    & = \sum_{i \in [m]} \sum_{k \in [c]} \Ibb(y^{(i)}=k) \log \Pbb(\xv^{(i)}, y^{(i)} = k | \alphav, \thetav) \\
    & = \sum_{i \in [m]} \sum_{k \in [c]} \Ibb(y^{(i)}=k) \log \Pbb(y^{(i)} = k | \alphav) \\ & \qquad \qquad \qquad + \sum_{i \in [m]} \sum_{k \in [c]} \Ibb(y^{(i)}=k) \log \Pbb(\xv^{(i)} | y^{(i)} = k, \thetav) \\[4pt]
    & = \sum_{k \in [c]} \sum_{i \in [m]} \underbrace{\Ibb(y^{(i)}=k) \log \alpha_k}_{\alphav~\text{相关的项}\qquad} + \sum_{k \in [c]} \sum_{i \in [m]} \underbrace{\Ibb(y^{(i)}=k) \log \Pbb(\xv^{(i)} | y^{(i)} = k, \thetav)}_{\thetav~\text{相关的项}\qquad}
\end{align*}
$$

<!-- slide data-notes="" -->

##### 极大似然估计

---

记$A_k = \sum_{i \in [m]} \Ibb(y^{(i)} = k)$为第$k$类样本数

$\alphav$相关的项

$$
\begin{align*}
    \qquad \max_{\alpha_k} ~ \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \alpha_k = \sum_{k \in [c]} A_k \log \alpha_k, \quad \st ~ \sum_{k \in [c]} \alpha_k = 1
\end{align*}
$$

拉格朗日函数$L = \sum \limits_{k \in [c]} A_k \log \alpha_k - \lambda ( \sum \limits_{k \in [c]} \alpha_k - 1 )$

$$
\begin{align*}
    \qquad \nabla_{\alpha_k} L  = \frac{A_k}{\alpha_k} - \lambda = 0 & \Longrightarrow \sum_{k \in [c]} A_k = \lambda \sum_{k \in [c]} \alpha_k = \lambda \\
    & \Longrightarrow \alpha_k = \frac{A_k}{\sum_{j \in [c]} A_j} = \frac{\text{第}k\text{类样本数}~~~}{\text{总样本数}}
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计

---

$\thetav$相关的项

$$
\begin{align*}
    \quad \mathrm{LL}(\thetav) & = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \Pbb(\xv^{(i)} | y^{(i)} = k, \thetav) \\
    & = \sum_{k \in [c]} \sum_{i \in [m]} \sum_{j \in [d]} \Ibb(y^{(i)}=k) \log \Pbb(x_j^{(i)} | y^{(i)} = k, \thetav) \\
    & = \sum_{k \in [c]} \sum_{i \in [m]} \sum_{j \in [d]} \Ibb(y^{(i)}=k) \log \prod_{l \in [n_j]} \Pbb( x_j^{(i)} = v_l^{(j)} | y=k)^{\Ibb(x_j^{(i)} = v_l^{(j)})} \\
    & = \sum_{k \in [c]} \sum_{j \in [d]} \sum_{l \in [n_j]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \Ibb(x_j^{(i)} = v_l^{(j)}) \log \theta_{jlk} \\
    & = \sum_{k \in [c]} \sum_{j \in [d]} \sum_{l \in [n_j]} B_{jlk} \log \theta_{jlk}
\end{align*}
$$

<div class="top-4"></div>

其中$B_{jlk}$是第$k$类样本中第$j$个特征取值$v_l^{(j)}$的样本数

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计

---

对任意给定的类别$k$和特征$j$，我们只需考虑

$$
\begin{align*}
    \quad \max_{\theta_{jlk}} ~ \sum_{l \in [n_j]} B_{jlk} \log \theta_{jlk}, \quad \st ~ \sum_{l \in [n_j]} \theta_{jlk} = 1
\end{align*}
$$

拉格朗日函数$L = \sum \limits_{l \in [n_j]} B_{jlk} \log \theta_{jlk} - \lambda ( \sum \limits_{l \in [n_j]} \theta_{jlk} - 1 )$

$$
\begin{align*}
    \quad & \nabla_{\theta_{jlk}} L = \frac{B_{jlk}}{\theta_{jlk}} - \lambda = 0 \Longrightarrow \sum_{l \in [n_j]} B_{jlk} = \lambda \sum_{l \in [n_j]} \theta_{jlk} = \lambda \\[4pt]
    & \Longrightarrow \theta_{jlk} = \frac{B_{jlk}}{\sum_{l \in [n_j]} B_{jlk}} = \frac{\text{第}k\text{类样本中第}j\text{个特征取值}v_l^{(j)}\text{的样本数}\qquad}{\text{第}k\text{类样本数}}
\end{align*}
$$

<!-- slide data-notes="" -->

##### 朴素贝叶斯算法

---

后验概率最大化：

$$
\begin{align*}
    \quad \mathop{\arg \max}_{y \in [c]} \Pbb(y|\xv) & = \mathop{\arg \max}_{y \in [c]} \Pbb(y) \Pbb(\xv | y) \\
    & = \mathop{\arg \max}_{y \in [c]} \Pbb(y) \Pbb(x_1 | y) \Pbb(x_2 | y) \cdots \Pbb(x_d | y)
\end{align*}
$$

根据数据集求

$$
\begin{align*}
    & \quad \Pbb(y = k) = \frac{\text{第}k\text{类样本数}~~~}{\text{总样本数}} \\
    & \quad \Pbb( x_j = v_l^{(j)} | y=k) = \frac{\text{第}k\text{类样本中第}j\text{个特征取值}v_l^{(j)}\text{的样本数}\qquad}{\text{第}k\text{类样本数}}
\end{align*}
$$

我的批注 朴素贝叶斯就是数数！

<!-- slide vertical=true data-notes="" -->

##### 朴素贝叶斯预测约会

---

<div class="threelines column7-border-right-solid head-highlight-1 tr-hover row9-border-top-dashed row18-border-top-solid top-3 fs9 left4 righta">

| 次序 | 时间 | 方式 | 天气 | 课业 | 疫情 | 电视 | 约会 |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  1   | 周六 | 吃饭 | 晴天 | 轻松 | 清零 | 精彩 |  是  |
|  2   | 周日 | 吃饭 | 阴天 | 轻松 | 清零 | 精彩 |  是  |
|  3   | 周日 | 吃饭 | 晴天 | 轻松 | 清零 | 精彩 |  是  |
|  4   | 周六 | 吃饭 | 阴天 | 轻松 | 清零 | 精彩 |  是  |
|  5   | 周间 | 吃饭 | 晴天 | 轻松 | 清零 | 精彩 |  是  |
|  6   | 周六 | 逛街 | 晴天 | 轻松 | 平缓 | 无聊 |  是  |
|  7   | 周日 | 逛街 | 晴天 | 适中 | 平缓 | 无聊 |  是  |
|  8   | 周日 | 逛街 | 晴天 | 轻松 | 平缓 | 精彩 |  是  |
|  9   | 周日 | 逛街 | 阴天 | 适中 | 平缓 | 精彩 |  否  |
|  10  | 周六 | 学习 | 雨天 | 轻松 | 严峻 | 无聊 |  否  |
|  11  | 周间 | 学习 | 雨天 | 繁重 | 严峻 | 精彩 |  否  |
|  12  | 周间 | 吃饭 | 晴天 | 繁重 | 严峻 | 无聊 |  否  |
|  13  | 周六 | 逛街 | 晴天 | 适中 | 清零 | 精彩 |  否  |
|  14  | 周间 | 逛街 | 阴天 | 适中 | 清零 | 精彩 |  否  |
|  15  | 周日 | 逛街 | 晴天 | 轻松 | 平缓 | 无聊 |  否  |
|  16  | 周间 | 吃饭 | 晴天 | 繁重 | 严峻 | 精彩 |  否  |
|  17  | 周六 | 吃饭 | 阴天 | 适中 | 平缓 | 精彩 |  否  |
|  18  | 周六 | 逛街 | 阴天 | 适中 | 清零 | 无聊 |  ？  |

</div>

<div class="top-60per left56per fs16">

$\Pbb(\text{约会}=\text{是})=8/17$
$\Pbb(\text{时间}=\text{周六}|\text{约会}=\text{是})=3/8$
$\Pbb(\text{方式}=\text{逛街}|\text{约会}=\text{是})=3/8$
$\Pbb(\text{天气}=\text{阴天}|\text{约会}=\text{是})=2/8$
$\Pbb(\text{课业}=\text{适中}|\text{约会}=\text{是})=1/8$
$\Pbb(\text{疫情}=\text{清零}|\text{约会}=\text{是})=5/8$
$\Pbb(\text{电视}=\text{无聊}|\text{约会}=\text{是})=2/8$

$\Pbb(\text{约会}=\text{否})=9/17$
$\Pbb(\text{时间}=\text{周六}|\text{约会}=\text{否})=3/9$
$\Pbb(\text{方式}=\text{逛街}|\text{约会}=\text{否})=4/9$
$\Pbb(\text{天气}=\text{阴天}|\text{约会}=\text{否})=3/9$
$\Pbb(\text{课业}=\text{适中}|\text{约会}=\text{否})=4/9$
$\Pbb(\text{疫情}=\text{清零}|\text{约会}=\text{否})=2/9$
$\Pbb(\text{电视}=\text{无聊}|\text{约会}=\text{否})=3/9$

<div class="top4"></div>

$\Large \frac{8}{17} \frac{3}{8} \frac{3}{8} \frac{2}{8} \frac{1}{8} \frac{5}{8}  \frac{2}{8} < \frac{9}{17} \frac{3}{9} \frac{4}{9} \frac{3}{9} \frac{4}{9} \frac{2}{9} \frac{3}{9}$

预测结果为“约会=否”

</div>

<!-- slide data-notes="" -->

##### 其它特征种类

---

设目标任务是文本分类，词汇表$\Vcal = \{ v_j \}_{j \in [d]}$，考虑三种情形：

<div class="top-2"></div>

$\Fbb = \{0,1\}$，$x_j = \Ibb(v_j\text{出现在文本}\xv\text{中})$，$\theta_{jk} = \Pbb (x_j = 1 | y = k)$

<div class="top1"></div>

$$
\begin{align*}
    \qquad \Pbb (\xv | y = k, \thetav) = \prod_{j \in [d]} \Pbb (x_j | y = k, \thetav) = \prod_{j \in [d]} \theta_{jk}^{x_j} (1 - \theta_{jk})^{1 - x_j}
\end{align*}
$$

<div class="top-4"></div>

注意这是$d$个独立的伯努利分布的乘积

<div class="top-2"></div>

$\Fbb = \Nbb$，词袋模型，文本的每个词依次从词汇表中随机选取生成

- $x_j$为词$v_j$在文本$\xv$中出现的次数
- $\theta_{jk}$为第$k$类文本选取词$v_j$的概率

<div class="top1"></div>

$$
\begin{align*}
    \qquad [\theta_{1k}; \ldots; \theta_{jk}; \ldots; \theta_{dk}] \in \Delta_d, ~ \Pbb (\xv | y = k, \thetav) = \frac{(x_1 + \cdots + x_d)!}{x_1! \cdots x_d!} \prod_{j \in [d]} \theta_{jk}^{x_j}
\end{align*}
$$

<div class="top-7"></div>

注意这是{==多项式分布==}

<!-- slide vertical=true data-notes="" -->

##### 其它特征种类

---

$\Fbb = \Rbb$，tf - idf 模型，$x_j \sim \Ncal(\mu_{jk}, \sigma_{jk}^2)$

$$
\begin{align*}
    \qquad \Pbb (\xv | y = k, \muv, \sigmav) = \prod_{j \in [d]} \frac{1}{\sqrt{2\pi \sigma_{jk}^2}} \exp \left( - \frac{(x_j - \mu_{jk})^2}{2 \sigma_{jk}^2} \right)
\end{align*}
$$

<div class="top-4"></div>

注意这是$d$个独立的高斯分布的乘积

<div class="top4"></div>

剩下只需用极大似然估计$\thetav, \muv, \sigmav$

<!-- slide data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">1</span>

---

$\Fbb = \{0,1\}$，$x_j = \Ibb(v_j\text{出现在文本}\xv\text{中})$，$\theta_{jk} = \Pbb (x_j = 1 | y = k)$

<div class="top1"></div>

$$
\begin{align*}
    \qquad \Pbb (\xv | y = k, \thetav) = \prod_{j \in [d]} \Pbb (x_j | y = k, \thetav) = \prod_{j \in [d]} \theta_{jk}^{x_j} (1 - \theta_{jk})^{1 - x_j}
\end{align*}
$$

对数似然函数中$\thetav$相关的项为

$$
\begin{align*}
    \qquad \mathrm{LL} (\thetav) & = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \Pbb (\xv^{(i)} | y^{(i)} = k, \thetav) \\
    & = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \prod_{j \in [d]} \theta_{jk}^{x_j^{(i)}} (1 - \theta_{jk})^{1 - x_j^{(i)}}        \\
    & = \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) (x_j^{(i)} \log \theta_{jk} + (1 - x_j^{(i)}) \log (1 - \theta_{jk}) ) \\
    & = \sum_{k \in [c]} \sum_{j \in [d]} (B_{jk} \log \theta_{jk} + \Bbar_{jk} \log (1 - \theta_{jk}) )
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">1</span>

---

对数似然函数中$\thetav$相关的项为

$$
\begin{align*}
    \qquad \mathrm{LL} (\thetav) & = \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) (x_j^{(i)} \log \theta_{jk} + (1 - x_j^{(i)}) \log (1 - \theta_{jk}) ) \\
    & = \sum_{k \in [c]} \sum_{j \in [d]} (B_{jk} \log \theta_{jk} + \Bbar_{jk} \log (1 - \theta_{jk}) )
\end{align*}
$$

<div class="top-4"></div>

其中

$$
\begin{align*}
    \qquad B_{jk} & = \sum_{i \in [m]} \Ibb(y^{(i)}=k) x_j^{(i)} = \text{第}k\text{类文本中包含词}v_j\text{的文本数} \\
    \Bbar_{jk} & = \sum_{i \in [m]} \Ibb(y^{(i)}=k) (1 - x_j^{(i)}) = \text{第}k\text{类文本中不包含词}v_j\text{的文本数}
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">1</span>

---

对数似然函数中$\thetav$相关的项为

$$
\begin{align*}
    \qquad & \mathrm{LL} (\thetav) = \sum_{k \in [c]} \sum_{j \in [d]} (B_{jk} \log \theta_{jk} + \Bbar_{jk} \log (1 - \theta_{jk}) ) \\
    & B_{jk} = \text{第}k\text{类文本中包含词}v_j\text{的文本数} \\
    & \Bbar_{jk} = \text{第}k\text{类文本中不包含词}v_j\text{的文本数}
\end{align*}
$$

对某个固定的$k$和$j$，估计$\theta_{jk}$只需求解优化问题

$$
\begin{align*}
    \qquad \max_{\theta_{jk}} ~ \{ B_{jk} \log \theta_{jk} + \Bbar_{jk} \log (1 - \theta_{jk}) \}
\end{align*}
$$

<div class="top-4"></div>

令关于$\theta_{jk}$的导数为零可得

$$
\begin{align*}
    \qquad \theta_{jk} = \frac{B_{jk}}{B_{jk} + \Bbar_{jk}} = \frac{\text{第}k\text{类文本中包含词}v_j\text{的文本数}\quad ~~~}{\text{第}k\text{类文本数}}
\end{align*}
$$

<!-- slide data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">2</span>

---

$\Fbb = \Nbb$，词袋模型，文本的每个词依次从词汇表中随机选取生成

- $x_j$为词$v_j$在文本$\xv$中出现的次数
- $\theta_{jk}$为第$k$类文本选取词$v_j$的概率

<div class="top1"></div>

$$
\begin{align*}
    \qquad [\theta_{1k}; \ldots; \theta_{jk}; \ldots; \theta_{dk}] \in \Delta_d, ~ \Pbb (\xv | y = k, \thetav) = \frac{(x_1 + \cdots + x_d)!}{x_1! \cdots x_d!} \prod_{j \in [d]} \theta_{jk}^{x_j}
\end{align*}
$$

<div class="top-4"></div>

对数似然函数中$\thetav$相关的项为

$$
\begin{align*}
    \qquad \mathrm{LL} (\thetav) & = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \Pbb (\xv^{(i)} | y^{(i)} = k, \thetav) \\
    & = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \left\{ \frac{(x_1 + \cdots + x_d)!}{x_1! \cdots x_d!} \prod_{j \in [d]} \theta_{jk}^{x_j^{(i)}} \right\} \\
    & = \const + \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) x_j^{(i)} \log \theta_{jk}
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">2</span>

---

对数似然函数中$\thetav$相关的项为

$$
\begin{align*}
    \qquad \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) x_j^{(i)} \log \theta_{jk} = \sum_{k \in [c]} \sum_{j \in [d]} B_{jk} \log \theta_{jk}
\end{align*}
$$

<div class="top-4"></div>

其中$B_{jk} = \sum_{i \in [m]} \Ibb(y^{(i)}=k) x_j^{(i)} = \text{词}v_j\text{在第}k\text{类文本中出现总次数}$

对某个固定的$k$，估计$\theta_{jk}$只需求解优化问题

$$
\begin{align*}
    \qquad \max_{\theta_{jk}} ~ \sum_{j \in [d]} B_{jk} \log \theta_{jk}, \quad \st ~ \sum_{j \in [d]} \theta_{jk} = 1
\end{align*}
$$

<div class="top-4"></div>

拉格朗日函数$L = \sum \limits_{j \in [d]} B_{jk} \log \theta_{jk} - \lambda ( \sum \limits_{j \in [d]} \theta_{jk} - 1 )$

$$
\begin{align*}
    \qquad \frac{\partial L}{\partial \theta_{jk}} = \frac{B_{jk}}{\theta_{jk}} - \lambda = 0 \Longrightarrow \theta_{jk} = \frac{\text{词}v_j\text{在第}k\text{类文本中出现总次数}\quad~~~}{\text{第}k\text{类文本的总词数}}
\end{align*}
$$

<!-- slide data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">3</span>

---

$\Fbb = \Rbb$，tf - idf 模型，$x_j \sim \Ncal(\mu_{jk}, \sigma_{jk}^2)$

$$
\begin{align*}
    \qquad \Pbb (\xv | y = k, \muv, \sigmav) = \prod_{j \in [d]} \frac{1}{\sqrt{2\pi \sigma_{jk}^2}} \exp \left( - \frac{(x_j - \mu_{jk})^2}{2 \sigma_{jk}^2} \right)
\end{align*}
$$

<div class="top-2"></div>

对数似然函数中$\muv, \sigmav$相关的项为

$$
\begin{align*}
    \qquad \mathrm{LL} & (\muv, \sigmav) = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \Pbb (\xv^{(i)} | y^{(i)} = k, \muv, \sigmav) \\
    & = \sum_{k \in [c]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \log \prod_{j \in [d]} \frac{1}{\sqrt{2\pi \sigma_{jk}^2}} \exp \left( - \frac{(x_j^{(i)} - \mu_{jk})^2}{2 \sigma_{jk}^2} \right) \\
    & = \const + \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \left( - \frac{(x_j^{(i)} - \mu_{jk})^2}{2 \sigma_{jk}^2} - \log \sigma_{jk}) \right)
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">3</span>

---

对数似然函数中$\muv, \sigmav$相关的项为

$$
\begin{align*}
    \qquad \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \left( - \frac{(x_j^{(i)} - \mu_{jk})^2}{2 \sigma_{jk}^2} - \log \sigma_{jk}) \right)
\end{align*}
$$

<div class="top-3"></div>

对某个固定的$k$和$j$，估计$\mu_{jk}$只需求解优化问题

$$
\begin{align*}
    \qquad \min_{\mu_{jk}} \sum_{i \in [m]} \Ibb(y^{(i)}=k) (x_j^{(i)} - \mu_{jk})^2
\end{align*}
$$

<div class="top-5"></div>

令关于$\mu_{jk}$的导数为零

$$
\begin{align*}
    \qquad \mu_{jk} & = \frac{\sum_{i \in [m]} \Ibb(y^{(i)}=k) x_j^{(i)}}{\sum_{i \in [m]} \Ibb(y^{(i)}=k)} = \frac{\text{第}k\text{类文本第}j\text{个特征的和}\quad~}{\text{第}k\text{类文本数}} \\[4pt]
    & = \text{第}k\text{类文本第}j\text{个特征的均值}
\end{align*}
$$

<!-- slide vertical=true data-notes="" -->

##### 极大似然估计 情形 <span style="font-weight:900">3</span>

---

对数似然函数中$\muv, \sigmav$相关的项为

$$
\begin{align*}
    \qquad \sum_{k \in [c]} \sum_{j \in [d]} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \left( - \frac{(x_j^{(i)} - \mu_{jk})^2}{2 \sigma_{jk}^2} - \log \sigma_{jk}) \right)
\end{align*}
$$

<div class="top-3"></div>

对某个固定的$k$和$j$，估计$\sigma_{jk}$只需求解优化问题

$$
\begin{align*}
    \qquad \min_{\sigma_{jk}} \sum_{i \in [m]} \Ibb(y^{(i)}=k) \left( \frac{(x_j^{(i)} - \mu_{jk})^2}{2 \sigma_{jk}^2} + \log \sigma_{jk}) \right)
\end{align*}
$$

<div class="top-5"></div>

令关于$\sigma_{jk}$的导数为零

$$
\begin{align*}
    \qquad \sigma_{jk} & = \sqrt{\frac{\sum_{i \in [m]} \Ibb(y^{(i)}=k) (x_j^{(i)} - \mu_{jk})^2}{\sum_{i \in [m]} \Ibb(y^{(i)}=k)}} \\
    & = \text{第}k\text{类文本第}j\text{个特征的标准差}
\end{align*}
$$

<!-- slide data-notes="" -->

##### 朴素贝叶斯预测约会

---

<div class="threelines column7-border-right-solid head-highlight-1 tr-hover row9-border-top-dashed row18-border-top-solid top-3 fs9 left4 righta">

| 次序 | 时间 | 方式 |    天气    | 课业 | 疫情 | 电视 | 约会 |
| :--: | :--: | :--: | :--------: | :--: | :--: | :--: | :--: |
|  1   | 周六 | 吃饭 |    晴天    | 轻松 | 清零 | 精彩 |  是  |
|  2   | 周日 | 吃饭 |    阴天    | 轻松 | 清零 | 精彩 |  是  |
|  3   | 周日 | 吃饭 |    晴天    | 轻松 | 清零 | 精彩 |  是  |
|  4   | 周六 | 吃饭 |    阴天    | 轻松 | 清零 | 精彩 |  是  |
|  5   | 周间 | 吃饭 |    晴天    | 轻松 | 清零 | 精彩 |  是  |
|  6   | 周六 | 逛街 |    晴天    | 轻松 | 平缓 | 无聊 |  是  |
|  7   | 周日 | 逛街 |    晴天    | 适中 | 平缓 | 无聊 |  是  |
|  8   | 周日 | 逛街 |    晴天    | 轻松 | 平缓 | 精彩 |  是  |
|  9   | 周日 | 逛街 |    阴天    | 适中 | 平缓 | 精彩 |  是  |
|  10  | 周六 | 学习 |    雨天    | 轻松 | 严峻 | 无聊 |  是  |
|  11  | 周间 | 学习 |    雨天    | 繁重 | 严峻 | 精彩 |  是  |
|  12  | 周间 | 吃饭 |    晴天    | 繁重 | 严峻 | 无聊 |  是  |
|  13  | 周六 | 逛街 |    晴天    | 适中 | 清零 | 精彩 |  是  |
|  14  | 周间 | 逛街 |    阴天    | 适中 | 清零 | 精彩 |  是  |
|  15  | 周日 | 逛街 |    晴天    | 轻松 | 平缓 | 无聊 |  是  |
|  16  | 周间 | 吃饭 |    晴天    | 繁重 | 严峻 | 精彩 |  是  |
|  17  | 周六 | 吃饭 |    阴天    | 适中 | 平缓 | 精彩 |  是  |
|  18  | 周六 | 逛街 | {==雨天==} | 适中 | 清零 | 无聊 |  ？  |

</div>

<div class="top-60per left56per fs16">

$\Pbb(\text{约会}=\text{否})=\class{blue}{0/17}$

<div class="top4"></div>

训练集中无负样本

模型无脑预测“约会=是”

</div>

<!-- slide vertical=true data-notes="" -->

##### 朴素贝叶斯预测约会

---

<div class="threelines column7-border-right-solid head-highlight-1 tr-hover row9-border-top-dashed row18-border-top-solid top-3 fs9 left4 righta">

| 次序 | 时间 | 方式 |    天气    | 课业 | 疫情 | 电视 | 约会 |
| :--: | :--: | :--: | :--------: | :--: | :--: | :--: | :--: |
|  1   | 周六 | 吃饭 |    晴天    | 轻松 | 清零 | 精彩 |  是  |
|  2   | 周日 | 吃饭 |    阴天    | 轻松 | 清零 | 精彩 |  是  |
|  3   | 周日 | 吃饭 |    晴天    | 轻松 | 清零 | 精彩 |  是  |
|  4   | 周六 | 吃饭 |    阴天    | 轻松 | 清零 | 精彩 |  是  |
|  5   | 周间 | 吃饭 |    晴天    | 轻松 | 清零 | 精彩 |  是  |
|  6   | 周六 | 逛街 |    晴天    | 轻松 | 平缓 | 无聊 |  是  |
|  7   | 周日 | 逛街 |    晴天    | 适中 | 平缓 | 无聊 |  是  |
|  8   | 周日 | 逛街 |    晴天    | 轻松 | 平缓 | 精彩 |  是  |
|  9   | 周日 | 逛街 |    阴天    | 适中 | 平缓 | 精彩 |  否  |
|  10  | 周六 | 学习 |    雨天    | 轻松 | 严峻 | 无聊 |  否  |
|  11  | 周间 | 学习 |    雨天    | 繁重 | 严峻 | 精彩 |  否  |
|  12  | 周间 | 吃饭 |    晴天    | 繁重 | 严峻 | 无聊 |  否  |
|  13  | 周六 | 逛街 |    晴天    | 适中 | 清零 | 精彩 |  否  |
|  14  | 周间 | 逛街 |    阴天    | 适中 | 清零 | 精彩 |  否  |
|  15  | 周日 | 逛街 |    晴天    | 轻松 | 平缓 | 无聊 |  否  |
|  16  | 周间 | 吃饭 |    晴天    | 繁重 | 严峻 | 精彩 |  否  |
|  17  | 周六 | 吃饭 |    阴天    | 适中 | 平缓 | 精彩 |  否  |
|  18  | 周六 | 逛街 | {==雨天==} | 适中 | 清零 | 无聊 |  ？  |

</div>

<div class="top-60per left56per fs16">

$\Pbb(\text{约会}=\text{是})=8/17$
$\Pbb(\text{时间}=\text{周六}|\text{约会}=\text{是})=3/8$
$\Pbb(\text{方式}=\text{逛街}|\text{约会}=\text{是})=3/8$
$\Pbb(\text{天气}=\class{blue}{\text{雨天}}|\text{约会}=\text{是})=\class{blue}{0/8}$
$\Pbb(\text{课业}=\text{适中}|\text{约会}=\text{是})=1/8$
$\Pbb(\text{疫情}=\text{清零}|\text{约会}=\text{是})=5/8$
$\Pbb(\text{电视}=\text{无聊}|\text{约会}=\text{是})=2/8$

<div class="top4"></div>

$\Large \frac{8}{17} \frac{3}{8} \frac{3}{8} \class{blue}{\frac{0}{8}} \frac{1}{8} \frac{5}{8}  \frac{2}{8} = \class{blue}{0}$

正样本中无“天气=雨天”的样本

似然乘积为零，其它特征不起作用

</div>

<!-- slide vertical=true data-notes="" -->

##### 拉普拉斯平滑

---

在各取值的频数上赋予一个正数$\lambda$，通常取$\lambda=1$

<div class="top2"></div>

$$
\begin{align*}
    & \qquad \Pbb (y = k) = \frac{\text{第}k\text{类样本数} + \lambda ~~~~}{\text{总样本数} + c \lambda} \\[6pt]
    & \qquad \Pbb ( x_j = v_l^{(j)} | y=k) = \frac{\text{第}k\text{类样本中第}j\text{个特征取值}v_l^{(j)}\text{的样本数} + \lambda \qquad ~}{\text{第}k\text{类样本数} + n_j \lambda} \\[6pt]
    & \qquad \Pbb (x_j = 1 | y = k) = \frac{\text{第}k\text{类文本中包含词}v_j\text{的文本数} + \lambda \quad ~~~}{\text{第}k\text{类文本数} + d \lambda} \\[6pt]
    & \qquad \Pbb (\text{选取词}v_j | y = k) = \frac{\text{词}v_j\text{在第}k\text{类文本中出现总次数} + \lambda \quad~~~}{\text{第}k\text{类文本的总词数} + d \lambda}
\end{align*}
$$
